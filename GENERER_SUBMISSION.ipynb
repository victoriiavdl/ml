{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ GÃ‰NÃ‰RER SUBMISSION KAGGLE\n",
    "\n",
    "**Objectif** : CrÃ©er submission.csv en une seule exÃ©cution\n",
    "\n",
    "**Ã‰tapes** :\n",
    "1. EntraÃ®ner RandomForest sur train.csv (avec mÃ©tÃ©o)\n",
    "2. Merger test.csv avec mÃ©tÃ©o 2013\n",
    "3. PrÃ©dire\n",
    "4. GÃ©nÃ©rer submission.csv\n",
    "\n",
    "**DurÃ©e** : ~2-3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ENTRAÃŽNER LE MODÃˆLE SUR TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[1/4] EntraÃ®nement du modÃ¨le...\")\n",
    "\n",
    "# Charger train\n",
    "df_train = pd.read_csv('data_plus/train_weather_merged_complete.csv')\n",
    "print(f\"âœ“ Train : {df_train.shape}\")\n",
    "\n",
    "# Features\n",
    "feature_cols = ['t', 'td', 'u', 'ff', 'vv', 'tminsol', 'nbas', 'n',\n",
    "                'rr24', 'rr12', 'rr6', 'pres', 'tn12', 'tx12',\n",
    "                'week_year', 'region_code']\n",
    "feature_cols = [c for c in feature_cols if c in df_train.columns]\n",
    "\n",
    "X_train = df_train[feature_cols].copy()\n",
    "y_train = df_train['TauxGrippe'].copy()\n",
    "\n",
    "# Imputer NaN\n",
    "medians = {}  # Garder les mÃ©dianes pour le test\n",
    "for col in X_train.columns:\n",
    "    medians[col] = X_train[col].median()\n",
    "    if X_train[col].isnull().sum() > 0:\n",
    "        X_train[col].fillna(medians[col], inplace=True)\n",
    "\n",
    "# EntraÃ®ner\n",
    "print(\"ðŸŒ² Random Forest...\")\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200, max_depth=15, min_samples_split=3,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ“ ModÃ¨le entraÃ®nÃ©\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHARGER TEST.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[2/4] Chargement test.csv...\")\n",
    "\n",
    "df_test = pd.read_csv('data_origin/test.csv')\n",
    "print(f\"âœ“ Test : {df_test.shape}\")\n",
    "print(f\"  Semaines : {df_test['week'].min()} -> {df_test['week'].max()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MERGER TEST AVEC MÃ‰TÃ‰O 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[3/4] Merge test + mÃ©tÃ©o 2013...\")\n",
    "\n",
    "# Mapping rÃ©gions -> stations\n",
    "MAPPING = {\n",
    "    'ALSACE': [7190, 7280], 'AQUITAINE': [7510, 7630],\n",
    "    'AUVERGNE': [7460, 7380], 'BASSE-NORMANDIE': [7027, 7139],\n",
    "    'BOURGOGNE': [7280, 7255], 'BRETAGNE': [7110, 7117, 7130],\n",
    "    'CENTRE': [7255, 7149], 'CHAMPAGNE-ARDENNE': [7072, 7168],\n",
    "    'CORSE': [7761, 7790], 'FRANCHE-COMTE': [7299, 7280],\n",
    "    'HAUTE-NORMANDIE': [7037, 7020], 'ILE-DE-FRANCE': [7150, 7149],\n",
    "    'LANGUEDOC-ROUSSILLON': [7630, 7643], 'LIMOUSIN': [7434, 7335],\n",
    "    'LORRAINE': [7090, 7180], 'MIDI-PYRENEES': [7630, 7627],\n",
    "    'NORD-PAS-DE-CALAIS': [7005, 7015], 'PAYS DE LA LOIRE': [7222, 7130],\n",
    "    'PICARDIE': [7005, 7015], 'POITOU-CHARENTES': [7335, 7255],\n",
    "    \"PROVENCE-ALPES-COTE D'AZUR\": [7650, 7690], 'RHONE-ALPES': [7481, 7482],\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for region, stations in MAPPING.items():\n",
    "    for station in stations:\n",
    "        rows.append({'numer_sta': station, 'region_name': region})\n",
    "df_mapping = pd.DataFrame(rows)\n",
    "\n",
    "# Charger synop 2013\n",
    "synop_files = sorted(glob.glob('DonneesMeteorologiques/DonneesMeteorologiques/synop.2013*.csv'))\n",
    "print(f\"  {len(synop_files)} fichiers synop\")\n",
    "\n",
    "stations_list = df_mapping['numer_sta'].unique().tolist()\n",
    "all_data = []\n",
    "\n",
    "for fpath in synop_files:\n",
    "    try:\n",
    "        df = pd.read_csv(fpath, sep=';', low_memory=False)\n",
    "        df = df[df['numer_sta'].isin(stations_list)]\n",
    "        if len(df) > 0:\n",
    "            all_data.append(df)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_synop = pd.concat(all_data, ignore_index=True)\n",
    "print(f\"  âœ“ MÃ©tÃ©o chargÃ©e\")\n",
    "\n",
    "# Convertir dates en semaines\n",
    "df_synop['date'] = pd.to_datetime(df_synop['date'], format='%Y%m%d%H%M%S', errors='coerce')\n",
    "df_synop['year'] = df_synop['date'].dt.isocalendar().year\n",
    "df_synop['week'] = df_synop['date'].dt.isocalendar().week\n",
    "df_synop['week_year'] = df_synop['year'] * 100 + df_synop['week']\n",
    "\n",
    "# Merger avec mapping\n",
    "df_synop = df_synop.merge(df_mapping, on='numer_sta', how='inner')\n",
    "\n",
    "# Variables mÃ©tÃ©o\n",
    "meteo_vars = ['t', 'td', 'u', 'ff', 'vv', 'tminsol', 'pres',\n",
    "              'rr24', 'rr12', 'rr6', 'tn12', 'tx12', 'nbas', 'n']\n",
    "\n",
    "for var in meteo_vars:\n",
    "    if var in df_synop.columns:\n",
    "        df_synop[var] = pd.to_numeric(df_synop[var], errors='coerce')\n",
    "\n",
    "# AgrÃ©ger par rÃ©gion et semaine\n",
    "vars_disponibles = [v for v in meteo_vars if v in df_synop.columns]\n",
    "agg_dict = {v: 'mean' for v in vars_disponibles}\n",
    "df_meteo = df_synop.groupby(['region_name', 'week_year'], as_index=False).agg(agg_dict)\n",
    "\n",
    "# Merger avec test\n",
    "df_test['region_clean'] = df_test['region_name'].str.upper().str.strip()\n",
    "df_meteo['region_clean'] = df_meteo['region_name'].str.upper().str.strip()\n",
    "\n",
    "df_test_merged = df_test.merge(\n",
    "    df_meteo,\n",
    "    left_on=['region_clean', 'week'],\n",
    "    right_on=['region_clean', 'week_year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"  âœ“ Merge OK : {df_test_merged.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PRÃ‰DIRE ET CRÃ‰ER SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[4/4] PrÃ©dictions et submission...\")\n",
    "\n",
    "# PrÃ©parer X_test\n",
    "X_test = df_test_merged[feature_cols].copy()\n",
    "\n",
    "# Imputer avec les mÃ©dianes du train\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].isnull().sum() > 0:\n",
    "        X_test[col].fillna(medians[col], inplace=True)\n",
    "\n",
    "# PrÃ©dire\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.maximum(0, np.round(predictions))  # >= 0, arrondi\n",
    "\n",
    "print(f\"âœ“ {len(predictions)} prÃ©dictions\")\n",
    "print(f\"  Min : {predictions.min():.0f}\")\n",
    "print(f\"  Max : {predictions.max():.0f}\")\n",
    "print(f\"  Moy : {predictions.mean():.1f}\")\n",
    "\n",
    "# CrÃ©er submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': df_test['Id'],\n",
    "    'TauxGrippe': predictions.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… SUBMISSION CRÃ‰Ã‰E!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFichier : submission.csv\")\n",
    "print(f\"Lignes  : {len(submission)}\")\n",
    "print(f\"\\nAperÃ§u :\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nStatistiques :\")\n",
    "print(submission['TauxGrippe'].describe())\n",
    "print(\"\\nðŸŽ¯ PrÃªt Ã  soumettre sur Kaggle!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
