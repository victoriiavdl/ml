# ğŸš€ KAGGLE INFLUENZA PREDICTION - GUIDE COMPLET

## ğŸ¯ Objectif
Maximiser le score sur le leaderboard Kaggle en prÃ©disant le taux de grippe pour 2012-2013.

---

## ğŸ“Š Contexte de la CompÃ©tition

- **Train** : 2004-2011 (9196 observations)
- **Test** : 2012-2013 (2288 observations - 104 semaines Ã— 22 rÃ©gions)
- **Gap** : On prÃ©dit **2 ans dans le futur** !

### ConsÃ©quences :
- âŒ Pas de lags directs possibles
- âœ… Mais on a les donnÃ©es mÃ©tÃ©o 2012-2013
- âœ… On peut utiliser des moyennes historiques (SECRET WEAPON)

---

## ğŸ—ï¸ Architecture de la Solution

### **Features utilisÃ©es** :

1. **Variables mÃ©tÃ©o** (12 variables)
   - TempÃ©rature, humiditÃ©, vent, visibilitÃ©, prÃ©cipitations, etc.

2. **Features temporelles cycliques** (7 variables)
   - Semaine de l'annÃ©e, mois, saison
   - sin/cos de la semaine et du mois (pour capturer la cyclicitÃ©)

3. **Moyennes historiques** ğŸš€ (6 variables - **SECRET WEAPON**)
   - `TauxGrippe_hist_week_mean` : moyenne pour cette rÃ©gion Ã  cette semaine de l'annÃ©e
   - `TauxGrippe_hist_month_mean` : moyenne pour cette rÃ©gion ce mois
   - `TauxGrippe_hist_season_mean` : moyenne pour cette rÃ©gion cette saison
   - `TauxGrippe_region_mean` : moyenne globale de la rÃ©gion
   - `TauxGrippe_region_std` : Ã©cart-type de la rÃ©gion
   - `TauxGrippe_week_global_mean` : moyenne globale pour cette semaine

4. **RÃ©gion** (1 variable)

**Total** : ~26 features

### **ModÃ¨les** :
- **XGBoost** (prioritÃ© #1)
- **LightGBM**
- **CatBoost**
- **Ensemble** : moyenne pondÃ©rÃ©e des 3 (basÃ©e sur leurs performances)

### **Validation** :
- Train : 2004-2010
- Validation : **2011** (mimique le test 2012-2013)
- RÃ©entraÃ®nement final : 2004-2011

---

## ğŸ“ Fichiers CrÃ©Ã©s

```
ğŸ“‚ ml/
â”œâ”€â”€ ğŸ““ KAGGLE_TRAIN_MODEL.ipynb       â† [1] EntraÃ®nement des modÃ¨les
â”œâ”€â”€ ğŸ““ KAGGLE_PREDICT.ipynb           â† [2] GÃ©nÃ©ration des prÃ©dictions
â”œâ”€â”€ ğŸ prepare_test_set.py            â† [0] PrÃ©paration du test (Ã  exÃ©cuter en premier!)
â”œâ”€â”€ ğŸ“„ README_KAGGLE.md               â† Ce fichier
â”‚
â”œâ”€â”€ ğŸ“‚ data_plus/
â”‚   â”œâ”€â”€ train_synop_cleaned_complet.csv    â† Train nettoyÃ©
â”‚   â””â”€â”€ test_synop_merged.csv              â† Test prÃ©parÃ© (aprÃ¨s step 0)
â”‚
â””â”€â”€ ğŸ“‚ (aprÃ¨s entraÃ®nement)
    â”œâ”€â”€ xgb_final.pkl, lgb_final.pkl, cat_final.pkl  â† ModÃ¨les
    â”œâ”€â”€ imputer.pkl, weights.pkl, features.pkl        â† Artifacts
    â”œâ”€â”€ submission_ensemble.csv                        â† FICHIER FINAL
    â”œâ”€â”€ feature_importance.csv                         â† Analyse
    â””â”€â”€ model_comparison.png, feature_importance.png   â† Visualisations
```

---

## ğŸš€ MARCHE Ã€ SUIVRE (3 Ã‰TAPES)

### **Ã‰TAPE 0 : PrÃ©parer le Test Set** â±ï¸ ~5 min

Le test set doit Ãªtre mergÃ© avec les donnÃ©es mÃ©tÃ©o 2012-2013.

```bash
# ExÃ©cuter le script de prÃ©paration
python3 prepare_test_set.py
```

**âœ… RÃ©sultat** : Fichier `data_plus/test_synop_merged.csv` crÃ©Ã©

---

### **Ã‰TAPE 1 : EntraÃ®ner les ModÃ¨les** â±ï¸ ~10-15 min

Ouvrir et exÃ©cuter toutes les cellules de `KAGGLE_TRAIN_MODEL.ipynb`

**Ce que Ã§a fait** :
1. Charge le train (2004-2011)
2. CrÃ©e les features temporelles + historiques
3. Split train/validation (2010/2011)
4. EntraÃ®ne XGBoost, LightGBM, CatBoost
5. Ã‰value les performances sur validation 2011
6. RÃ©entraÃ®ne sur toutes les donnÃ©es (2004-2011)
7. Sauvegarde les modÃ¨les

**âœ… RÃ©sultats attendus** :
- RMSE validation ~50-80 (dÃ©pend des donnÃ©es)
- RÂ² > 0.8
- ModÃ¨les sauvegardÃ©s (*.pkl)

---

### **Ã‰TAPE 2 : GÃ©nÃ©rer les PrÃ©dictions** â±ï¸ ~2 min

Ouvrir et exÃ©cuter toutes les cellules de `KAGGLE_PREDICT.ipynb`

**Ce que Ã§a fait** :
1. Charge les modÃ¨les entraÃ®nÃ©s
2. Charge le test set (2012-2013)
3. CrÃ©e les mÃªmes features qu'au train
4. GÃ©nÃ¨re les prÃ©dictions avec les 3 modÃ¨les
5. Combine en ensemble (moyenne pondÃ©rÃ©e)
6. CrÃ©e `submission_ensemble.csv`

**âœ… RÃ©sultat final** : `submission_ensemble.csv` prÃªt Ã  soumettre !

---

## ğŸ“¤ SOUMISSION SUR KAGGLE

1. Aller sur la page de la compÃ©tition Kaggle
2. Onglet "Submit Predictions"
3. Upload `submission_ensemble.csv`
4. Attendre le score !

### Si vous voulez tester les modÃ¨les individuellement :
Le notebook gÃ©nÃ¨re aussi :
- `submission_xgb.csv`
- `submission_lgb.csv`
- `submission_cat.csv`

Vous pouvez les soumettre sÃ©parÃ©ment pour comparer.

---

## ğŸ”§ OPTIMISATIONS POSSIBLES (si temps)

### 1. **Hyperparameter Tuning**
Utiliser GridSearch ou Optuna pour optimiser :
- `max_depth`, `learning_rate`, `n_estimators`
- `subsample`, `colsample_bytree`

### 2. **Feature Engineering AvancÃ©**
- Interactions : `t Ã— u` (tempÃ©rature Ã— humiditÃ©)
- Google Trends (donnÃ©es mensuelles disponibles)
- Lag des moyennes historiques
- Rolling std des features mÃ©tÃ©o

### 3. **Ensemble AvancÃ©**
- Stacking (meta-model)
- Blending avec diffÃ©rents poids

### 4. **ModÃ¨les SupplÃ©mentaires**
- Neural Networks (LSTM pour sÃ©ries temporelles)
- Prophet (Facebook)
- ARIMA par rÃ©gion

---

## ğŸ“Š ANALYSE DES RÃ‰SULTATS

### **Feature Importance**
AprÃ¨s l'entraÃ®nement, vÃ©rifiez `feature_importance.csv` :
- Les features historiques doivent Ãªtre dans le top 5-10
- Les variables mÃ©tÃ©o (t, u) sont importantes
- Les features cycliques (week_sin, month_sin) capturent la saisonnalitÃ©

### **Validation**
- RMSE sur 2011 doit Ãªtre cohÃ©rent avec le test 2012-2013
- Si RMSE validation >> RMSE train â†’ overfitting
- Si RMSE validation â‰ˆ RMSE train â†’ bon modÃ¨le

---

## â“ TROUBLESHOOTING

### ProblÃ¨me : "ModuleNotFoundError: No module named 'pandas'"
**Solution** :
```bash
pip install pandas numpy scikit-learn xgboost lightgbm catboost matplotlib seaborn
```

### ProblÃ¨me : "FileNotFoundError: test_synop_merged.csv"
**Solution** : ExÃ©cutez d'abord `python3 prepare_test_set.py`

### ProblÃ¨me : "MÃ©moire insuffisante"
**Solutions** :
- RÃ©duire `n_estimators` (500 â†’ 200)
- ExÃ©cuter sur Google Colab (gratuit, GPU)
- Utiliser un sous-ensemble pour le dev

### ProblÃ¨me : "NaN dans les prÃ©dictions"
**Cause** : Features manquantes dans le test
**Solution** : VÃ©rifier que toutes les features du train sont dans le test

---

## ğŸ“ CONCEPTS CLÃ‰S UTILISÃ‰S

1. **Validation temporelle** : Split 2010/2011 au lieu de shuffle
2. **Features cycliques** : sin/cos pour capturer la pÃ©riodicitÃ© annuelle
3. **Moyennes historiques** : Exploiter les patterns saisonniers par rÃ©gion
4. **Ensemble methods** : Combiner plusieurs modÃ¨les rÃ©duit la variance
5. **Early stopping** : Ã‰vite l'overfitting

---

## ğŸ“ˆ SCOREESTIMÃ‰

Avec cette stratÃ©gie :
- **Baseline** (mÃ©tÃ©o seule) : RMSE ~80-100
- **Avec features temporelles** : RMSE ~60-80
- **Avec moyennes historiques** ğŸš€ : RMSE ~40-60
- **Ensemble optimisÃ©** : RMSE ~35-50

**Top 10%** de la compÃ©tition attendu ! ğŸ†

---

## ğŸ“ BESOIN D'AIDE ?

1. VÃ©rifiez les messages d'erreur dans les notebooks
2. VÃ©rifiez `feature_importance.csv` pour comprendre les features
3. Comparez les RMSE train/validation pour diagnostiquer overfitting
4. Testez avec un sous-ensemble de donnÃ©es d'abord

---

## ğŸš€ BONNE CHANCE !

**StratÃ©gie gagnante** :
1. âœ… ExÃ©cuter prepare_test_set.py
2. âœ… ExÃ©cuter KAGGLE_TRAIN_MODEL.ipynb
3. âœ… ExÃ©cuter KAGGLE_PREDICT.ipynb
4. âœ… Soumettre submission_ensemble.csv
5. ğŸ‰ Profiter du top 10% !

---

**Date de crÃ©ation** : 2025-12-16
**Version** : 1.0
**Auteur** : StratÃ©gie optimisÃ©e pour maximiser le score Kaggle
