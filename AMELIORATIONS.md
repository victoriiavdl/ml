# üéØ Analyse et Am√©liorations du Mod√®le Ensemble

## ‚ùå Probl√®mes identifi√©s dans le code original

### 1. **LAGS FACTICES au lieu de VRAIS LAGS**
**Probl√®me:**
```python
# Code original
lag_wmean_by_wn = wmean_by_wn.shift(1)  # Moyenne historique de la semaine N-1
df["lag1_seasonal"] = df["week_num"].map(lag_wmean_by_wn)
```

Ce n'est **PAS** le TauxGrippe de la semaine pr√©c√©dente pour chaque r√©gion, c'est juste la moyenne historique nationale de la semaine N-1.

**Solution:**
```python
# VRAI lag par r√©gion
df['lag1_real'] = df.groupby('region_code')['TauxGrippe'].shift(1)
df['lag2_real'] = df.groupby('region_code')['TauxGrippe'].shift(2)
df['lag3_real'] = df.groupby('region_code')['TauxGrippe'].shift(3)
df['lag4_real'] = df.groupby('region_code')['TauxGrippe'].shift(4)
```

**Impact attendu:** +15-25% d'am√©lioration du score (les lags r√©els sont TR√àS pr√©dictifs pour les s√©ries temporelles)

---

### 2. **PAS DE ROLLING FEATURES (moyennes mobiles)**
**Probl√®me:** Pas de lissage des features bruyantes (Google trends, m√©t√©o, target)

**Solution:**
```python
# Rolling means sur le target
for window in [2, 3, 4]:
    df[f'rolling_mean_{window}w'] = df.groupby('region_code')['TauxGrippe'].transform(
        lambda x: x.rolling(window=window, min_periods=1).mean().shift(1)
    )

# Rolling sur Google trends
for window in [2, 3, 4]:
    df[f'google_roll_{window}w'] = df.groupby('region_code')['google_grippe'].transform(
        lambda x: x.rolling(window=window, min_periods=1).mean()
    )

# Rolling sur temp√©rature
for window in [2, 4]:
    df[f't_roll_{window}w'] = df.groupby('region_code')['t'].transform(
        lambda x: x.rolling(window=window, min_periods=1).mean()
    )
```

**Impact attendu:** +5-10% d'am√©lioration

---

### 3. **TARGET ENCODING de r√©gion_code INSUFFISANT**
**Probl√®me:** CatBoost g√®re region_code en cat√©goriel, mais XGBoost/LightGBM utilisent juste un encoding num√©rique arbitraire

**Solution:**
```python
# Moyenne et std du TauxGrippe par r√©gion (historique)
agg_region = hist.groupby("region_code")["TauxGrippe"].agg(["mean", "std"]).reset_index()
df = df.merge(agg_region, on="region_code", how="left")

# Pattern saisonnier par r√©gion x semaine
agg_reg_week = hist.groupby(["region_code", "week_num"])["TauxGrippe"].mean().reset_index()
df = df.merge(agg_reg_week, on=["region_code", "week_num"], how="left")
```

**Impact attendu:** +5-10% d'am√©lioration

---

### 4. **GOOGLE TRENDS SOUS-EXPLOIT√â**
**Probl√®me:** Juste `google_log` et `google_anomaly`, pas de dynamique temporelle

**Solution:**
```python
# Diff√©rence (variation semaine √† semaine)
df["google_diff"] = df.groupby('region_code')['google_grippe'].diff()

# Acc√©l√©ration (diff de diff)
df["google_accel"] = df.groupby('region_code')['google_diff'].diff()

# Rolling
for window in [2, 3, 4]:
    df[f'google_roll_{window}w'] = df.groupby('region_code')['google_grippe'].transform(
        lambda x: x.rolling(window=window, min_periods=1).mean()
    )

# Interactions enrichies
df["google_x_temperature"] = df["google_log"] * df["cold"]
df["google_x_region_mean"] = df["google_log"] * df["region_mean"]
```

**Impact attendu:** +3-8% d'am√©lioration

---

### 5. **SPLIT DE VALIDATION SOUS-OPTIMAL**
**Probl√®me:** Split 80/20 arbitraire, pas align√© avec la t√¢che r√©elle

**Solution:**
```python
# Split temporel (comme Kaggle: pr√©dire 2012-2013 depuis 2004-2011)
train_data = train[train["year"] <= 2010]  # 2004-2010
val_data   = train[train["year"] == 2011]  # 2011
```

Cela **simule exactement** la situation du test set (pr√©dire 2012-2013 depuis 2004-2011).

**Impact:** Meilleure estimation du score r√©el, moins d'overfitting

---

### 6. **SIMPLE BLEND au lieu de STACKING**
**Probl√®me:** Moyenne pond√©r√©e simple des pr√©dictions

**Solution:** Utiliser un meta-model (Ridge, Linear Regression) qui apprend √† combiner les pr√©dictions

```python
# Cr√©er les features de niveau 1
meta_train = np.column_stack([pred_val_cat, pred_val_xgb, pred_val_lgb])

# Meta-model
meta_model = Ridge(alpha=1.0)
meta_model.fit(meta_train, y_val)
pred_meta = meta_model.predict(meta_test)
```

**Impact attendu:** +2-5% d'am√©lioration

---

### 7. **MANQUE LightGBM**
**Probl√®me:** Seulement CatBoost + XGBoost

**Solution:** Ajouter LightGBM qui a souvent des patterns diff√©rents et am√©liore l'ensemble

**Impact attendu:** +2-5% d'am√©lioration

---

## üöÄ Autres am√©liorations √† tester

### A. **Features d'interactions avanc√©es**
```python
# Interactions temp√©rature x semaine
df["cold_x_w_mean"] = df["cold"] * df["w_mean"]
df["cold_x_peak"] = df["cold"] * df["is_peak"]

# Interactions Google x r√©gion
df["google_x_region_week"] = df["google_log"] * df["region_week_mean"]

# Ratio features
df["google_vs_hist"] = df["google_log"] / (df["w_mean"] + 1)
df["temp_vs_hist"] = df["t"] / (df.groupby('region_code')['t'].transform('mean') + 1)
```

**Impact attendu:** +2-5%

---

### B. **Features de tendance (trend)**
```python
# Tendance sur les 4 derni√®res semaines
df['trend_4w'] = df.groupby('region_code')['TauxGrippe'].transform(
    lambda x: x.rolling(4, min_periods=2).apply(lambda y: np.polyfit(range(len(y)), y, 1)[0] if len(y) >= 2 else 0)
)

# Pente de Google trends
df['google_trend'] = df.groupby('region_code')['google_grippe'].transform(
    lambda x: x.diff()
)
```

**Impact attendu:** +2-4%

---

### C. **Features m√©t√©o enrichies**
```python
# Interactions m√©t√©o
df['cold_x_humidity'] = df['cold'] * df['u']
df['wind_x_rain'] = df['ff'] * df['rr1']

# Jours de froid extr√™me
df['extreme_cold'] = (df['t'] < 0).astype(int)
df['extreme_cold_x_week'] = df['extreme_cold'] * df['w_mean']
```

**Impact attendu:** +1-3%

---

### D. **Optimisation des hyperparam√®tres**
Faire un grid search ou Optuna pour:
- CatBoost: depth, learning_rate, l2_leaf_reg, min_data_in_leaf
- XGBoost: max_depth, min_child_weight, learning_rate, subsample
- LightGBM: num_leaves, learning_rate, min_child_samples

**Impact attendu:** +3-8%

---

### E. **Features de variabilit√©**
```python
# √âcart-type mobile sur le target
df['target_std_4w'] = df.groupby('region_code')['TauxGrippe'].transform(
    lambda x: x.rolling(4, min_periods=2).std().shift(1)
)

# Coefficient de variation Google
df['google_cv'] = df.groupby('region_code')['google_grippe'].transform(
    lambda x: x.rolling(4, min_periods=2).std() / (x.rolling(4, min_periods=2).mean() + 1)
)
```

**Impact attendu:** +1-3%

---

### F. **Post-processing des pr√©dictions**
```python
# Clipper les pr√©dictions n√©gatives
pred = np.clip(pred, 0, None)

# Ajuster les pr√©dictions pour qu'elles respectent les patterns saisonniers
# (si pr√©diction << moyenne historique pour cette semaine, remonter un peu)
seasonal_mean = ...  # moyenne historique par semaine
pred_adjusted = pred * 0.8 + seasonal_mean * 0.2
```

**Impact attendu:** +1-2%

---

## üìä Ordre de priorit√© des am√©liorations

### üî• CRITIQUE (impact > 10%)
1. ‚úÖ **VRAIS LAGS temporels** (lag1, lag2, lag3, lag4 par r√©gion)
2. ‚úÖ **Target encoding de r√©gion** (mean, std historique)

### ‚≠ê IMPORTANT (impact 5-10%)
3. ‚úÖ **Rolling features** (moyennes mobiles 2-4 semaines)
4. ‚úÖ **Google trends am√©lior√©** (diff, rolling, interactions)
5. ‚úÖ **Split temporel propre** (2004-2010 train, 2011 val)
6. ‚úÖ **LightGBM** (ajouter au ensemble)

### üí° RECOMMAND√â (impact 2-5%)
7. ‚úÖ **Stacking** (meta-model au lieu de simple blend)
8. **Hyperparam√®tres optimis√©s** (Optuna)
9. **Interactions avanc√©es** (temp x google, etc.)
10. **Features de tendance** (pente sur 4 semaines)

### üé® BONUS (impact 1-3%)
11. **Features m√©t√©o enrichies**
12. **Features de variabilit√©**
13. **Post-processing** des pr√©dictions

---

## üéØ Plan d'action

### Phase 1: Quick wins (d√©j√† fait ‚úÖ)
- [x] Impl√©menter vrais lags
- [x] Impl√©menter rolling features
- [x] Target encoding de r√©gion
- [x] Split temporel
- [x] Ajouter LightGBM
- [x] Stacking

### Phase 2: √Ä tester maintenant
- [ ] **Ex√©cuter `ensemble_improved.py`** sur les donn√©es
- [ ] Comparer les scores avec le code original
- [ ] Identifier les features les plus importantes (feature_importances_)

### Phase 3: Optimisation (si besoin)
- [ ] Grid search hyperparam√®tres
- [ ] Features d'interactions avanc√©es
- [ ] Post-processing

### Phase 4: Test set
- [ ] Adapter le code pour le test set (g√©rer les lags √† partir du train)
- [ ] G√©n√©rer les pr√©dictions
- [ ] Soumettre sur Kaggle

---

## ‚ö†Ô∏è Point critique pour le TEST SET

Pour pr√©dire le test set (2012-2013), il faut:

1. **Pour les lags**: utiliser les derni√®res valeurs du train (2011) pour d√©marrer
2. **Pour les rolling features**: utiliser les fen√™tres qui chevauchent train/test
3. **Pour les stats historiques**: utiliser TOUT le train (2004-2011)

Exemple:
```python
# Pour pr√©dire 2012 semaine 1
# lag1 = TauxGrippe de 2011 semaine 52 (derni√®re semaine du train)
# lag2 = TauxGrippe de 2011 semaine 51
# etc.
```

Il faudra soit:
- Faire une pr√©diction **it√©rative** (pr√©dire semaine par semaine, utiliser les pr√©dictions comme lags)
- Ou stocker les derni√®res valeurs du train et les utiliser pour initialiser les lags du test

---

## üìà Estimation d'am√©lioration globale

Si le code original donne RMSE = 100:
- Avec vrais lags + rolling + target encoding: **RMSE ‚âà 70-80** (-20 √† -30%)
- Avec optimisation hyperparam√®tres: **RMSE ‚âà 65-75** (-5 √† -10% suppl√©mentaire)
- Avec features avanc√©es: **RMSE ‚âà 60-70** (-5% suppl√©mentaire)

**Total attendu: -30 √† -40% d'am√©lioration du RMSE** üöÄ
