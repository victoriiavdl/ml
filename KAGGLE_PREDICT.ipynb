{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ G√âN√âRATION DES PR√âDICTIONS KAGGLE\n",
    "\n",
    "**Ce notebook**:\n",
    "1. Charge les mod√®les entra√Æn√©s\n",
    "2. Pr√©pare le test set (2012-2013) avec les m√™mes features\n",
    "3. G√©n√®re les pr√©dictions\n",
    "4. Cr√©e le fichier submission.csv\n",
    "\n",
    "**‚ö†Ô∏è Pr√©requis**: Avoir ex√©cut√© KAGGLE_TRAIN_MODEL.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Imports r√©ussis!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CHARGEMENT DES MOD√àLES ENTRA√éN√âS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Charger les mod√®les\n",
    "print(\"üì¶ Chargement des mod√®les...\")\n",
    "with open('xgb_final.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "with open('lgb_final.pkl', 'rb') as f:\n",
    "    lgb_model = pickle.load(f)\n",
    "with open('cat_final.pkl', 'rb') as f:\n",
    "    cat_model = pickle.load(f)\n",
    "with open('imputer.pkl', 'rb') as f:\n",
    "    imputer = pickle.load(f)\n",
    "with open('weights.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "with open('features.pkl', 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "\n",
    "print(f\"‚úì Mod√®les charg√©s!\")\n",
    "print(f\"‚úì Features: {len(features)}\")\n",
    "print(f\"‚úì Poids ensemble: {weights}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHARGEMENT DU TEST SET\n",
    "\n",
    "**Important**: On doit d'abord merger le test avec les donn√©es m√©t√©o 2012-2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# OPTION 1: Si vous avez d√©j√† un fichier test_synop_merged.csv\n",
    "# df_test = pd.read_csv('data_plus/test_synop_merged.csv')\n",
    "\n",
    "# OPTION 2: Charger le test brut et le merger avec les donn√©es m√©t√©o\n",
    "# (Code de merge √† ajouter - similaire au train)\n",
    "\n",
    "# Pour l'instant, on suppose que vous devez cr√©er ce fichier\n",
    "print(\"‚ö†Ô∏è IMPORTANT:\")\n",
    "print(\"Vous devez d'abord cr√©er le test set avec les donn√©es m√©t√©o 2012-2013\")\n",
    "print(\"Voir le script de pr√©paration du test ci-dessous...\")\n",
    "\n",
    "# PLACEHOLDER - √Ä adapter selon votre structure\n",
    "# df_test = pd.read_csv('data_origin/test.csv')\n",
    "# Puis merger avec donn√©es m√©t√©o 2012-2013 comme fait pour le train"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PR√âPARATION DU TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cette cellule suppose que df_test est charg√© et a les colonnes m√©t√©o\n",
    "# Similaires √† df_train_full\n",
    "\n",
    "def prepare_test_set(df_test, df_train_full):\n",
    "    \"\"\"\n",
    "    Pr√©parer le test set avec les M√äMES features que le train\n",
    "    \"\"\"\n",
    "    df_test = df_test.copy()\n",
    "    \n",
    "    # Convertir date\n",
    "    # Cr√©er date √† partir de week_year si n√©cessaire\n",
    "    def week_to_datetime(week_str):\n",
    "        year = int(str(week_str)[:4])\n",
    "        week = int(str(week_str)[4:6])\n",
    "        from datetime import datetime\n",
    "        jan4 = datetime(year, 1, 4)\n",
    "        week_one_monday = jan4 - pd.Timedelta(days=jan4.weekday())\n",
    "        return week_one_monday + pd.Timedelta(weeks=week-1)\n",
    "    \n",
    "    if 'date' not in df_test.columns:\n",
    "        df_test['date'] = df_test['week'].apply(week_to_datetime)\n",
    "    df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "    \n",
    "    # Ajouter saison\n",
    "    def get_season(date):\n",
    "        month = date.month\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Hiver'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Printemps'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Ete'\n",
    "        else:\n",
    "            return 'Automne'\n",
    "    \n",
    "    df_test['saison'] = df_test['date'].apply(get_season)\n",
    "    \n",
    "    # Features temporelles\n",
    "    df_test['year'] = df_test['date'].dt.year\n",
    "    df_test['month'] = df_test['date'].dt.month\n",
    "    df_test['week_of_year'] = df_test['date'].dt.isocalendar().week\n",
    "    df_test['day_of_year'] = df_test['date'].dt.dayofyear\n",
    "    \n",
    "    # Features cycliques\n",
    "    df_test['week_sin'] = np.sin(2 * np.pi * df_test['week_of_year'] / 52)\n",
    "    df_test['week_cos'] = np.cos(2 * np.pi * df_test['week_of_year'] / 52)\n",
    "    df_test['month_sin'] = np.sin(2 * np.pi * df_test['month'] / 12)\n",
    "    df_test['month_cos'] = np.cos(2 * np.pi * df_test['month'] / 12)\n",
    "    \n",
    "    # Encoder saison\n",
    "    saison_map = {'Hiver': 1, 'Printemps': 2, 'Ete': 3, 'Automne': 4}\n",
    "    df_test['saison_encoded'] = df_test['saison'].map(saison_map)\n",
    "    \n",
    "    # üéØ FEATURES HISTORIQUES - Calcul√©es depuis le TRAIN\n",
    "    # Cr√©er les mappings depuis le train\n",
    "    hist_week_map = df_train_full.groupby(['region_code', 'week_of_year'])['TauxGrippe'].mean().to_dict()\n",
    "    hist_month_map = df_train_full.groupby(['region_code', 'month'])['TauxGrippe'].mean().to_dict()\n",
    "    hist_season_map = df_train_full.groupby(['region_code', 'saison'])['TauxGrippe'].mean().to_dict()\n",
    "    region_mean_map = df_train_full.groupby('region_code')['TauxGrippe'].mean().to_dict()\n",
    "    region_std_map = df_train_full.groupby('region_code')['TauxGrippe'].std().to_dict()\n",
    "    week_global_map = df_train_full.groupby('week_of_year')['TauxGrippe'].mean().to_dict()\n",
    "    \n",
    "    # Appliquer au test\n",
    "    df_test['TauxGrippe_hist_week_mean'] = df_test.apply(\n",
    "        lambda x: hist_week_map.get((x['region_code'], x['week_of_year']), region_mean_map.get(x['region_code'], 0)),\n",
    "        axis=1\n",
    "    )\n",
    "    df_test['TauxGrippe_hist_month_mean'] = df_test.apply(\n",
    "        lambda x: hist_month_map.get((x['region_code'], x['month']), region_mean_map.get(x['region_code'], 0)),\n",
    "        axis=1\n",
    "    )\n",
    "    df_test['TauxGrippe_hist_season_mean'] = df_test.apply(\n",
    "        lambda x: hist_season_map.get((x['region_code'], x['saison']), region_mean_map.get(x['region_code'], 0)),\n",
    "        axis=1\n",
    "    )\n",
    "    df_test['TauxGrippe_region_mean'] = df_test['region_code'].map(region_mean_map)\n",
    "    df_test['TauxGrippe_region_std'] = df_test['region_code'].map(region_std_map)\n",
    "    df_test['TauxGrippe_week_global_mean'] = df_test['week_of_year'].map(week_global_map)\n",
    "    \n",
    "    return df_test\n",
    "\n",
    "print(\"‚úì Fonction de pr√©paration du test d√©finie\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Charger le train pour les stats historiques\n",
    "df_train_full = pd.read_csv('data_plus/train_synop_cleaned_complet.csv')\n",
    "df_train_full['date'] = pd.to_datetime(df_train_full['date'])\n",
    "\n",
    "# Charger et pr√©parer le test\n",
    "# ‚ö†Ô∏è √Ä ADAPTER: Charger votre test set avec les donn√©es m√©t√©o\n",
    "# df_test = pd.read_csv('data_plus/test_synop_merged.csv')\n",
    "# df_test = prepare_test_set(df_test, df_train_full)\n",
    "\n",
    "print(\"‚ö†Ô∏è Veuillez charger votre test set avec les donn√©es m√©t√©o 2012-2013\")\n",
    "print(\"   Puis appliquer: df_test = prepare_test_set(df_test, df_train_full)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. G√âN√âRATION DES PR√âDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cette cellule suppose que df_test est pr√©par√©\n",
    "\n",
    "# Pr√©parer X_test\n",
    "X_test = df_test[features]\n",
    "test_ids = df_test['Id']\n",
    "\n",
    "# Imputer\n",
    "X_test = pd.DataFrame(\n",
    "    imputer.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(f\"‚úì Test set pr√©par√©: {X_test.shape}\")\n",
    "\n",
    "# Pr√©dictions avec les 3 mod√®les\n",
    "print(\"\\nüöÄ G√©n√©ration des pr√©dictions...\")\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"‚úì XGBoost\")\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "print(\"‚úì LightGBM\")\n",
    "\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "print(\"‚úì CatBoost\")\n",
    "\n",
    "# Ensemble (moyenne pond√©r√©e)\n",
    "y_pred = (\n",
    "    weights['XGBoost'] * y_pred_xgb +\n",
    "    weights['LightGBM'] * y_pred_lgb +\n",
    "    weights['CatBoost'] * y_pred_cat\n",
    ")\n",
    "print(\"‚úì Ensemble\")\n",
    "\n",
    "# S'assurer que les pr√©dictions sont positives\n",
    "y_pred = np.maximum(y_pred, 0)\n",
    "\n",
    "print(f\"\\nüìä Statistiques des pr√©dictions:\")\n",
    "print(f\"   Min: {y_pred.min():.2f}\")\n",
    "print(f\"   Max: {y_pred.max():.2f}\")\n",
    "print(f\"   Moyenne: {y_pred.mean():.2f}\")\n",
    "print(f\"   M√©diane: {np.median(y_pred):.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CR√âATION DU FICHIER SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cr√©er le fichier submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'TauxGrippe': y_pred\n",
    "})\n",
    "\n",
    "# Sauvegarder\n",
    "submission.to_csv('submission_ensemble.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ FICHIER SUBMISSION CR√â√â!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Fichier: submission_ensemble.csv\")\n",
    "print(f\"Lignes: {len(submission)}\")\n",
    "print(f\"\\nAper√ßu:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nüéØ Pr√™t √† soumettre sur Kaggle!\")\n",
    "print(\"=\"*80)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (OPTIONNEL) CR√âER DES SUBMISSIONS INDIVIDUELLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Si vous voulez tester les mod√®les individuellement\n",
    "\n",
    "# XGBoost\n",
    "submission_xgb = pd.DataFrame({'Id': test_ids, 'TauxGrippe': np.maximum(y_pred_xgb, 0)})\n",
    "submission_xgb.to_csv('submission_xgb.csv', index=False)\n",
    "\n",
    "# LightGBM\n",
    "submission_lgb = pd.DataFrame({'Id': test_ids, 'TauxGrippe': np.maximum(y_pred_lgb, 0)})\n",
    "submission_lgb.to_csv('submission_lgb.csv', index=False)\n",
    "\n",
    "# CatBoost\n",
    "submission_cat = pd.DataFrame({'Id': test_ids, 'TauxGrippe': np.maximum(y_pred_cat, 0)})\n",
    "submission_cat.to_csv('submission_cat.csv', index=False)\n",
    "\n",
    "print(\"‚úì Submissions individuelles cr√©√©es:\")\n",
    "print(\"  - submission_xgb.csv\")\n",
    "print(\"  - submission_lgb.csv\")\n",
    "print(\"  - submission_cat.csv\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
