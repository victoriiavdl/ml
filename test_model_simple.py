#!/usr/bin/env python3
"""Test d'un modÃ¨le simple pour prÃ©dire le TauxGrippe"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("MODÃˆLE SIMPLE - PRÃ‰DICTION TAUX GRIPPE")
print("="*80)

# ============================================================================
# 1. CHARGER LES DONNÃ‰ES
# ============================================================================
print("\n[1/5] Chargement des donnÃ©es...")
df = pd.read_csv('data_plus/train_weather_merged_complete.csv')
print(f"âœ“ {df.shape[0]} lignes, {df.shape[1]} colonnes")

# ============================================================================
# 2. PRÃ‰PARATION DES DONNÃ‰ES
# ============================================================================
print("\n[2/5] PrÃ©paration des features...")

# Variables Ã  utiliser comme features
feature_cols = [
    # Variables mÃ©tÃ©o principales
    't', 'td', 'u', 'ff', 'vv', 'dd',           # TempÃ©rature, humiditÃ©, vent
    'tminsol', 'nbas', 'n',                     # Sol, nÃ©bulositÃ©
    'rr1', 'rr3', 'rr6', 'rr12', 'rr24',       # PrÃ©cipitations
    'pres', 'tn12', 'tx12',                     # Pression, temp min/max
    'rafper', 'per', 'ht_neige',                # Vent, neige
    # Variables temporelles
    'week_year',
    'region_code'
]

# Garder seulement les colonnes qui existent
feature_cols = [c for c in feature_cols if c in df.columns]
print(f"  Features utilisÃ©es : {len(feature_cols)}")

# Target
target = 'TauxGrippe'

# CrÃ©er X et y
X = df[feature_cols].copy()
y = df[target].copy()

# GÃ©rer les NaN (imputation simple par la mÃ©diane)
print(f"  NaN avant imputation : {X.isnull().sum().sum()}")
for col in X.columns:
    if X[col].isnull().sum() > 0:
        X[col].fillna(X[col].median(), inplace=True)
print(f"  NaN aprÃ¨s imputation : {X.isnull().sum().sum()}")

# ============================================================================
# 3. SPLIT TRAIN/TEST
# ============================================================================
print("\n[3/5] Split train/test...")

# Split temporel : 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True
)

print(f"  Train : {X_train.shape[0]} lignes")
print(f"  Test  : {X_test.shape[0]} lignes")

# ============================================================================
# 4. ENTRAÃNEMENT DU MODÃˆLE
# ============================================================================
print("\n[4/5] EntraÃ®nement Random Forest...")

model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)
print("âœ“ ModÃ¨le entraÃ®nÃ©")

# ============================================================================
# 5. Ã‰VALUATION
# ============================================================================
print("\n[5/5] Ã‰valuation...")

# PrÃ©dictions
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# MÃ©triques Train
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
mae_train = mean_absolute_error(y_train, y_pred_train)
r2_train = r2_score(y_train, y_pred_train)

# MÃ©triques Test
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
mae_test = mean_absolute_error(y_test, y_pred_test)
r2_test = r2_score(y_test, y_pred_test)

print("\n" + "="*80)
print("RÃ‰SULTATS")
print("="*80)

print("\nğŸ“Š MÃ‰TRIQUES TRAIN:")
print(f"  RMSE : {rmse_train:.2f}")
print(f"  MAE  : {mae_train:.2f}")
print(f"  RÂ²   : {r2_train:.4f}")

print("\nğŸ“Š MÃ‰TRIQUES TEST:")
print(f"  RMSE : {rmse_test:.2f}")
print(f"  MAE  : {mae_test:.2f}")
print(f"  RÂ²   : {r2_test:.4f}")

# Feature importance
print("\nğŸ“ˆ TOP 10 FEATURES IMPORTANTES:")
importances = pd.DataFrame({
    'feature': feature_cols,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

for i, row in importances.head(10).iterrows():
    print(f"  {row['feature']:15s} : {row['importance']:.4f}")

# Exemples de prÃ©dictions
print("\nğŸ” EXEMPLES DE PRÃ‰DICTIONS (TEST):")
print(f"{'RÃ©el':>8s} {'PrÃ©dit':>8s} {'Erreur':>8s}")
print("-" * 26)
for i in range(min(10, len(y_test))):
    real = y_test.iloc[i]
    pred = y_pred_test[i]
    err = abs(real - pred)
    print(f"{real:8.1f} {pred:8.1f} {err:8.1f}")

print("\n" + "="*80)
print("âœ“ TERMINÃ‰!")
print("="*80)

# Sauvegarder les prÃ©dictions
results = pd.DataFrame({
    'TauxGrippe_reel': y_test,
    'TauxGrippe_predit': y_pred_test
})
results.to_csv('predictions_test.csv', index=False)
print("\nğŸ’¾ PrÃ©dictions sauvegardÃ©es : predictions_test.csv")
